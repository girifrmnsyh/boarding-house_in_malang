{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b57e0d",
   "metadata": {},
   "source": [
    "# Overview\n",
    "### English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24fe9d",
   "metadata": {},
   "source": [
    "#### In (Step 3) I have created a model to predict boarding prices using ML (Machine Learning) & the data I obtained in scraping (Step 1). After evaluation, it turned out that my model was far from expected. The model could not predict the data well and had a very high error value.\n",
    "#### So this time I decided to improve the model with the information I got in EDA (Step 4) previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcf3f14",
   "metadata": {},
   "source": [
    "# Ringkasan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b62b8",
   "metadata": {},
   "source": [
    "### Bahasa Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41238076",
   "metadata": {},
   "source": [
    "#### pada (Step 3) saya sudah membuat model untuk memprediksi harga kos dengan ML (Machine Learning) & data yang saya peroleh dalam scraping (Step 1). Setelah di evaluasi ternyata model saya jauh dari yang diharapkan, Model itu tidak dapat memprediksi data dengan baik dan memiliki nilai error yang sangat tinggi.\n",
    "#### Jadi kali ini saya memutuskan untuk improve model tersebut dengan informasi informasi yang saya dapatkan di EDA (Step 4) Sebelumnya. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea850f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_kos_malang_clean.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc5829",
   "metadata": {},
   "source": [
    "# Data Spliting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4069c",
   "metadata": {},
   "source": [
    "#### This time I tried to use the \"Ratings\" column also as a feature because there is information that can be useful (According to EDA in Step 3) and removed the \"Location\" column because it has no effect on predicting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e62090",
   "metadata": {},
   "source": [
    "#### Kali ini saya mencoba untuk menggunakan kolom \"Ratings\" juga sebagai fitur karena ada informasi yang bisa berguna (Menurut EDA pada Step 3) dan menghapus kolom \"Lokasi\" karena tidak berpengaruh untuk memprediksi model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# drop colum Lokasi & Nama\n",
    "data.drop(['Nama Kos','Lokasi'], axis=1, inplace=True)\n",
    "\n",
    "# define Feature (X) & Label (y)\n",
    "X = data.drop('Harga per Bulan', axis=1)\n",
    "y = data['Harga per Bulan']\n",
    "\n",
    "# spliting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                   test_size=0.25,\n",
    "                                                   random_state=42)\n",
    "\n",
    "# check \n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db9dd1",
   "metadata": {},
   "source": [
    "# Make Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129244ea",
   "metadata": {},
   "source": [
    "#### First I will create a function to get data on the number of boarding facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda4601",
   "metadata": {},
   "source": [
    "#### Pertama saya akan membuat fungsi untuk mendapatkan data berapa jumlah fasilitas kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb56e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_facilities(DATA):\n",
    "    \n",
    "    # copy data\n",
    "    D = DATA.copy(deep=True)\n",
    "    \n",
    "    # looping for get data\n",
    "    for i in D.index:\n",
    "        d = len(D.loc[i, 'Fasilitas'].split(', '))\n",
    "        D.loc[i, 'Jumlah Fasilitas'] = d\n",
    "        \n",
    "    return D\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de292ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check fungtion\n",
    "get_count_facilities(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d48004",
   "metadata": {},
   "source": [
    "#### Secondly, I will separate each facility column and assign a value [0, 1] to each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb844ca",
   "metadata": {},
   "source": [
    "#### Yang kedua saya akan memisah setiap kolom fasilitas dan memberikan nilai [0, 1] pada setiap kolomnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4ff934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_facilities(DATA):\n",
    "    \n",
    "    # unique values\n",
    "    unique_facility = ['WiFi', 'Kasur', 'Akses 24 Jam', 'K. Mandi Dalam', 'Kloset Duduk', 'AC']\n",
    "    \n",
    "    # list for new unique value\n",
    "    wifi = []\n",
    "    kasur = []\n",
    "    akses = []\n",
    "    KMD = []\n",
    "    KD = []\n",
    "    AC = []\n",
    "\n",
    "    D = DATA.copy(deep=True) # copy dataframe\n",
    "    \n",
    "    # looping for index in colum of dataframe\n",
    "    for d in D['Fasilitas']:\n",
    "        L = d.split(', ') # split value\n",
    "        \n",
    "        for uf,new in zip(unique_facility,[wifi, kasur, akses, KMD, KD, AC]):\n",
    "            if uf in L:\n",
    "                new.append(1)\n",
    "            else:\n",
    "                new.append(0)\n",
    "    \n",
    "    D.drop('Fasilitas', axis=1, inplace=True)\n",
    "    new_df = pd.DataFrame({\n",
    "        'Wifi': wifi,\n",
    "        'Kasur': kasur,\n",
    "        'Akses 24 Jam': akses,\n",
    "        'K. Mandi Dalam': KMD,\n",
    "        'Kloset Duduk': KD,\n",
    "        'AC': AC\n",
    "    })\n",
    "    \n",
    "    # suitable index\n",
    "    new_df.index = D.index\n",
    "    \n",
    "    return pd.concat([D, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebe8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "get_facilities(get_count_facilities(X_train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ad48a",
   "metadata": {},
   "source": [
    "#### Last Step, I want to bin the rating column where if the rating is > 3 then the value is 2, if <=3 the value is 0 and if there is no data (nan) then the value is 0, the resulting output will be 0,1,2 (sequentially) based on the average price obtained from the previous EDA (Step 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4b916",
   "metadata": {},
   "source": [
    "#### Yang terakhir, saya mau binig kolom rating dimana jika rating > 3 maka nilainya 2, jika <=3 nilainya 0 dan jika tidak ada data (nan) maka nilainya 0, output yang dihasilkan adalah 0,1,2 (berurutan) berdasarkan rata rata harga yang diperoleh dari EDA (Step 4) sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14a38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bining_ratings(DATA):\n",
    "    \n",
    "    # copy data\n",
    "    D = DATA.copy(deep=True)\n",
    "    \n",
    "    # looping for get data\n",
    "    for i in D.index:\n",
    "        d = D.loc[i, 'Ratings']\n",
    "        \n",
    "        # decision\n",
    "        if d > 3:\n",
    "            D.loc[i, 'Ratings'] = 2\n",
    "        elif d <= 3:\n",
    "            D.loc[i, 'Ratings'] = 0\n",
    "        else:\n",
    "            D.loc[i, 'Ratings'] = 1\n",
    "        \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c93050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check function output\n",
    "bining_ratings(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc53ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f88cb5",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe24fe2",
   "metadata": {},
   "source": [
    "#### Create a pipeline to process the dataframe until it is ready for use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6293d",
   "metadata": {},
   "source": [
    "#### Membuat pipeline untuk memproses dataframe hingga siap digunakan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required package\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8e1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "\n",
    "df_pipeline = Pipeline([\n",
    "    ('GCF',FunctionTransformer(get_count_facilities)),\n",
    "    ('GF',FunctionTransformer(get_facilities)),\n",
    "    ('BR',FunctionTransformer(bining_ratings))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88960ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "df_pipeline.fit_transform(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e135cd8",
   "metadata": {},
   "source": [
    "#### create a model and tuning pipeline to get the best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdd242",
   "metadata": {},
   "source": [
    "#### membuat pipeline model dan tuning untuk mendapatkan paramter terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model param\n",
    "param_grid = {\n",
    "    'algo__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'algo__C': [0.1, 1, 10, 100],\n",
    "    'algo__gamma': ['scale', 'auto'],\n",
    "    'algo__epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# model pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('df_pipeline', df_pipeline),\n",
    "    ('scaler', MinMaxScaler(feature_range=(0,1))),\n",
    "    ('algo', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034bba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuning model\n",
    "model = GridSearchCV(pipeline, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d15e8",
   "metadata": {},
   "source": [
    "# Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab06259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate data\n",
    "print(f'best param : {model.best_params_}')\n",
    "print(f'Validation : {model.score(X_train, y_train)}')\n",
    "print(f'Testing : {model.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e090b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation model prediction & actual data.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# make prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "sns.lineplot(x=range(1,len(X_test)+1), y=y_test, label='Data Actual')\n",
    "sns.lineplot(x=range(1,len(X_test)+1), y=y_pred, label='Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e728fc",
   "metadata": {},
   "source": [
    "# Improvement Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ecd3d3",
   "metadata": {},
   "source": [
    "#### Improve the model by trying different feature range tuning in each colum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10a9678",
   "metadata": {},
   "source": [
    "#### Improvement model dengan mencoba tuning feature range berbeda di setiap kolomnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1119e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check n cols after df transformation\n",
    "df_pipeline.transform(X_train).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# make column transformer for scaler\n",
    "scaler_each_colum = ColumnTransformer([\n",
    "    ('scl_ratings', MinMaxScaler(), ['Ratings']),\n",
    "    ('scl_cf', MinMaxScaler(), ['Jumlah Fasilitas']),\n",
    "    ('scl_f', MinMaxScaler(), ['Wifi', 'Kasur', 'Akses 24 Jam', \n",
    "                               'K. Mandi Dalam', 'Kloset Duduk', 'AC'])\n",
    "])\n",
    "\n",
    "# pipeline model\n",
    "pipeline2 = Pipeline([\n",
    "    ('df_pipeline', df_pipeline),\n",
    "    ('scaler', scaler_each_colum),\n",
    "    ('algo', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e870a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "params = {\n",
    "    'scaler__scl_ratings__feature_range' : [(0,1),(0,2),(0,3),(0,5)],\n",
    "    'scaler__scl_cf__feature_range' : [(0,1),(0,2),(0,3),(0,5)],\n",
    "    'scaler__scl_f__feature_range' : [(0,1),(0,2),(0,3),(0,5)], \n",
    "    'algo__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'algo__C': [0.1, 1, 10, 100],\n",
    "    'algo__gamma': ['scale', 'auto'],\n",
    "    'algo__epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model2 = RandomizedSearchCV(pipeline2, param_distributions=params, scoring='neg_mean_squared_error', n_iter=50, n_jobs=-1, verbose=1)\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ac1f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195fd19",
   "metadata": {},
   "source": [
    "# Evaluasi Model part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d348812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate data\n",
    "print(f'best param : {model2.best_params_}')\n",
    "print(f'Validation : {model2.score(X_train, y_train)}')\n",
    "print(f'Testing : {model2.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation model prediction & actual data.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# make prediction\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "sns.lineplot(x=range(1,len(X_test)+1), y=y_test, label='Data Actual')\n",
    "sns.lineplot(x=range(1,len(X_test)+1), y=y_pred, label='Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9667b",
   "metadata": {},
   "source": [
    "# Improvement Model part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d691a8",
   "metadata": {},
   "source": [
    "#### Change the bolean value in each facility column, based on the order of the average cost price for the facility and the results are added (SUM) and divided by the number of facilities (Facility Sum) to make a new column (Value)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265a4d1",
   "metadata": {},
   "source": [
    "#### Mengubah nilai bolean pada setiap kolom fasilitas, berdasarkat urutan harga rata rata kos berdasarkar fasilitas tersebut dan hasilnya ditambahkan (SUM) dan di bagi banyak fasilitas (Jumlah Fasilitas) untuk dijadikan kolom baru (Value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b30fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to handle the task above\n",
    "def get_value_facilities(DATA):\n",
    "    \n",
    "    # unique values\n",
    "    unique_facility = ['WiFi', 'Kasur', 'Akses 24 Jam', 'K. Mandi Dalam', 'Kloset Duduk', 'AC']\n",
    "    \n",
    "    # list for value_facilities\n",
    "    value_of_facilities = []\n",
    "\n",
    "    D = DATA.copy(deep=True) # copy dataframe\n",
    "    \n",
    "    # looping for index in colum of dataframe\n",
    "    for d in D['Fasilitas']:\n",
    "        L = d.split(', ') # split value\n",
    "        \n",
    "        value = 0 # value each data\n",
    "        \n",
    "        # filter and get value \n",
    "        for uf,v in zip(unique_facility, [3,2,1,5,4,6]):\n",
    "            if uf in L:\n",
    "                value += v\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        value_of_facilities.append(value)\n",
    "        \n",
    "    \n",
    "    D.drop('Fasilitas', axis=1, inplace=True) # drop original colum\n",
    "    \n",
    "    new_df = pd.DataFrame({\n",
    "        'Jumlah Value' : value_of_facilities\n",
    "    }, index=D.index)\n",
    "    D = pd.concat([D, new_df], axis=1)\n",
    "    D['Value'] = D['Jumlah Value'] / D['Jumlah Fasilitas']\n",
    "    return D.drop('Jumlah Value', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline model\n",
    "df_pipeline3 = Pipeline([\n",
    "    ('GCF',FunctionTransformer(get_count_facilities)),\n",
    "    ('GF',FunctionTransformer(get_value_facilities)),\n",
    "    ('BR',FunctionTransformer(bining_ratings))\n",
    "])\n",
    "\n",
    "scaler_each_colum3 = ColumnTransformer([\n",
    "    ('scl_ratings', MinMaxScaler(), ['Ratings']),\n",
    "    ('scl_cf', MinMaxScaler(), ['Jumlah Fasilitas']),\n",
    "    ('scl_vf', MinMaxScaler(), ['Value'])\n",
    "])\n",
    "\n",
    "pipeline3 = Pipeline([\n",
    "    ('df_pipeline', df_pipeline3),\n",
    "    ('scaler', scaler_each_colum3),\n",
    "    ('algo', SVR())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61424cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pipeline3.fit_transform(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5710d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "params = {\n",
    "    'scaler__scl_ratings__feature_range' : [(0,1),(0,2),(0,3),(0,5)],\n",
    "    'scaler__scl_cf__feature_range' : [(0,1),(0,2),(0,3),(0,5)],\n",
    "    'scaler__scl_vf__feature_range' : [(0,1),(0,2),(0,3),(0,5)], \n",
    "    'algo__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'algo__C': [0.1, 1, 10, 100],\n",
    "    'algo__gamma': ['scale', 'auto'],\n",
    "    'algo__epsilon': [0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model3 = RandomizedSearchCV(pipeline3, param_distributions=params, scoring='neg_mean_squared_error', n_iter=50, n_jobs=-1, verbose=1)\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51084422",
   "metadata": {},
   "source": [
    "# Evaluasi Model part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate data\n",
    "print(f'best param : {model3.best_params_}')\n",
    "print(f'Validation : {model3.score(X_train, y_train)}')\n",
    "print(f'Testing : {model3.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ab9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation model prediction & actual data.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# make prediction\n",
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "sns.lineplot(x=range(1,len(X_test)+1), y=y_test, label='Data Actual')\n",
    "sns.lineplot(x=range(1,len(X_test)+1), y=y_pred, label='Model')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e8238",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "#### Here you can see that the best model (with the fewest errors) is in the model2 variable, so I decided to save that model as the final project. It should be noted that this model is not perfect, in fact, in my opinion, it is not good due to the lack of feature data and the data volume is still relatively small.\n",
    "### Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971692d5",
   "metadata": {},
   "source": [
    "# Kesimpulan \n",
    "#### Disini terlihat bahwa model yang paling bagus (paling sedikit error) ada pada variabel model2, jadi saya memutuskan untuk menyimpan model tersebut sebagai final project. Harus diketahui bahwa model ini belum sempurna bahkan menurut saya kurang bagus dikarenakan kurangnya data fitur dan volume data yang masih relatif kecil.\n",
    "### Terima kasih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model/svm_regression_v2.pkl','wb') as file:\n",
    "    pickle.dump(model2, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd4a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:employee_project]",
   "language": "python",
   "name": "conda-env-employee_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
